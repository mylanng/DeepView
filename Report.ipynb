{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10839369-2ba7-4d07-8a7d-ea8de1870d36",
   "metadata": {},
   "source": [
    "## COMPUTER VISION: A Deep Learning Model for Ultrasound Imaging in Non-Destructive Testing ##\n",
    "\n",
    "#### Team BOOST: My Lan Nguyen, Harry Hoang, Donald Nguyen "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd89ddf",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "This project addresses a critical challenge in volumetric data processing: converting raw 3D ultrasound scans into structured surface meshes. Specifically, the dataset comprises volumetric scans of steel pipes, with or without objects inside and debris/dirt at the bottom. The goal is to estimate accurate 3D surface meshes that represent these scans for applications such as industrial inspection and modeling.\n",
    "\n",
    "Through a combination of advanced preprocessing techniques, a 3D Convolutional Neural Network (3D-CNN) backbone, and robust evaluation metrics, this project aims to provide a scalable solution to surface mesh estimation. The following notebook documents the entire process, from data exploration to model training and evaluation, leveraging the dataset provided by the competition organizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c63aec1-84af-40ba-a0d9-cbfed32d655f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\my lan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.18.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\my lan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\my lan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\my lan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\my lan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\my lan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\my lan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\my lan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\my lan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\my lan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\my lan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.25.5)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\my lan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\my lan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\my lan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\my lan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\my lan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\my lan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\my lan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.67.1)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\my lan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\my lan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in c:\\users\\my lan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\my lan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\my lan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\my lan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\my lan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.45.0)\n",
      "Requirement already satisfied: rich in c:\\users\\my lan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\users\\my lan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\my lan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\my lan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\my lan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\my lan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\my lan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\my lan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\my lan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\my lan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\my lan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\my lan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\my lan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\my lan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df64e92e-492b-4e58-a07c-a752b2c550e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "import trimesh\n",
    "import os\n",
    "from scipy.ndimage import zoom\n",
    "import gc \n",
    "import gc\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8619e4",
   "metadata": {},
   "source": [
    "### Data Exploration and Preprocessing\n",
    "\n",
    "#### Understanding the Data\n",
    "The dataset consists of 3D ultrasound scans of steel pipes, some with objects inside or debris at the bottom. These scans are paired with corresponding 3D meshes that represent the structure captured in the scans.\n",
    "- Training Data: 89 scans with only 5 having matching 3D meshes for reference.\n",
    "- Testing Data: 10 scans, all with corresponding 3D meshes.\n",
    "Each scan comes with detailed metadata, such as dimensions and spacing, which helps us align and interpret the data accurately. This context is vital for understanding the challenge: how do we train a model to produce high-quality surface meshes from these scans?\n",
    "\n",
    "#### Data Visualization\n",
    "To get a sense of what we’re working with, we visualized the volumetric scans and meshes using ParaView. This step helped us see how the data fits together:\n",
    "- The steel pipes are clearly visible as dense regions in the scans.\n",
    "- Additional details like objects inside the pipes and debris at the bottom\n",
    "add complexity.\n",
    "- The provided 3D meshes are impressive—they capture the geometry of the pipes and their contents beautifully and serve as a gold standard for training and evaluation.\n",
    "Seeing the data this way gave us confidence in the task but also highlighted the challenges we’d need to overcome, like the limited number of reference meshes for training.\n",
    "\n",
    "#### Preprocessing: Getting the Data Ready\n",
    "Before feeding the data into our model, we needed to clean it up and make it consistent. This involved two main steps: preparing the scans and standardizing the meshes.\n",
    "##### Preparing the Scans\n",
    "- Scaling: The raw data is scaled to ensure all scans are on the same intensity range. This makes it easier for the model to learn meaningful patterns.\n",
    "- Resizing: Scans are downscaled from their original size to something more manageable for our model. We found that 128x128x128 was a sweet spot between detail and efficiency.\n",
    "- Consistency: A channel dimension is added to make the data compatible with our 3D-CNN model.\n",
    "##### Standardizing the Meshes\n",
    "- Centering and Scaling: Meshes are adjusted so their coordinates are centered and scaled to fit inside a unit sphere. This keeps everything uniform and easier for the model to learn.\n",
    "- Equalizing Vertices: Each mesh is adjusted to have exactly 10,000 vertices, either by padding smaller ones with zeros or trimming larger ones.\n",
    "\n",
    "##### Challenges We Faced\n",
    "Getting the data ready was relatively challenging, as we were struggling with extremely massive scans. We had to try multiple models and modify the code frequently to reduce the files without losing important details. We also had troubles with limited training data. With only 5 reference meshes for 89 training scans, we needed to design our model carefully to generalize well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df47dd6",
   "metadata": {},
   "source": [
    "### Model Design\n",
    "The goal of this project is to estimate detailed 3D surface meshes from raw volumetric scans, which is a non-trivial task requiring the model to learn complex spatial patterns. To tackle this, we designed a custom deep learning architecture tailored for 3D data, combining the power of convolutional neural networks (CNNs) and fully connected layers. The model is both robust and efficient, striking a balance between performance and computational feasibility.\n",
    "\n",
    "#### Key Features of the Model\n",
    "Our model, named VolumetricToMeshModel, has two main components:\n",
    "1. 3D-CNN Backbone\n",
    "The backbone is built with 3D convolutional layers that extract meaningful spatial features from the volumetric scans. Think of this as the brain of the model—it processes the scan data to identify patterns like edges, textures, and shapes.\n",
    "- It uses several layers of 3D convolutions, followed by batch normalization to stabilize learning and max pooling to reduce dimensionality.\n",
    "- At the end, we apply global average pooling to compress all the extracted features into a compact representation.\n",
    "2. Fully Connected Layers for Regression\n",
    "After the backbone processes the volumetric data, the output is passed to fully connected layers. These layers predict the coordinates of the 3D vertices for the mesh. Essentially, this part of the model translates abstract features into precise spatial points.\n",
    "- The final layer outputs the x, y, and z coordinates for all vertices, ensuring the predicted mesh has the same structure as the reference meshes.\n",
    "\n",
    "#### Model Architecture Overview\n",
    "Here’s a breakdown of the model’s architecture:\n",
    "- Input Layer: Takes in volumetric data of shape (128, 128, 128, 1). We downscaled the data to make it easier for our computer to process.\n",
    "- 3D-CNN Layers: A sequence of convolutional layers (16, 32, 64, and 128 filters) to capture spatial details.\n",
    "- Pooling Layers: Reduce the dimensionality of the data while preserving key features.\n",
    "- Fully Connected Layers: Process the features extracted by the CNN to predict vertex coordinates.\n",
    "- Output Layer: Produces a final set of 3D points, reshaped into a (batch_size, num_vertices, 3) format.\n",
    "\n",
    "#### Why a 3D-CNN?\n",
    "We chose a 3D-CNN because volumetric data is inherently three-dimensional. A traditional 2D-CNN would lose depth information, which is critical for accurately estimating surface meshes. The 3D convolutions allow the model to learn spatial patterns in all three dimensions, making it well-suited for this task.\n",
    "\n",
    "#### Training Details\n",
    "- Loss Function: Mean Squared Error (MSE) between predicted and ground truth vertex coordinates. This ensures the model minimizes the distance between the predicted mesh and the actual mesh.\n",
    "- Optimizer: Adam optimizer with a learning rate of 0.0001, chosen for its efficiency and adaptability.\n",
    "- Output Shape: The model predicts 10,000 vertices, each with x, y, and z coordinates, for a total output shape of (batch_size, 10,000, 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79c597dd-8d2d-4bb6-abcb-1fe1c6075ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VolumetricToMeshModel(tf.keras.Model):\n",
    "    def __init__(self, latent_dim=1024, num_vertices=10000):\n",
    "        super(VolumetricToMeshModel, self).__init__()\n",
    "\n",
    "        # 3D-CNN Backbone\n",
    "        self.backbone = models.Sequential([\n",
    "            layers.Conv3D(16, kernel_size=3, strides=1, padding=\"same\", activation=\"relu\"),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.MaxPooling3D(pool_size=2, strides=2),\n",
    "\n",
    "            layers.Conv3D(32, kernel_size=3, strides=1, padding=\"same\", activation=\"relu\"),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.MaxPooling3D(pool_size=2, strides=2),\n",
    "\n",
    "            layers.Conv3D(64, kernel_size=3, strides=1, padding=\"same\", activation=\"relu\"),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.MaxPooling3D(pool_size=2, strides=2),\n",
    "\n",
    "            layers.Conv3D(128, kernel_size=3, strides=1, padding=\"same\", activation=\"relu\"),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.GlobalAveragePooling3D()\n",
    "        ])\n",
    "\n",
    "        # Fully connected layers for regression\n",
    "        self.fc = models.Sequential([\n",
    "            layers.Dense(latent_dim, activation=\"relu\"),\n",
    "            layers.Dense(num_vertices * 3)  # Predict x, y, z for each vertex\n",
    "        ])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.backbone(inputs)\n",
    "        x = self.fc(x)\n",
    "        return tf.reshape(x, (-1, tf.shape(x)[1] // 3, 3))  # Output shape: (batch_size, num_vertices, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ccf04de9-451d-4fe6-a6f0-7400b6009d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VolumetricMeshDataset(tf.data.Dataset):\n",
    "    def __new__(cls, volumes_dir, meshes_dir, input_shape=(128, 128, 128), num_vertices=10000):\n",
    "        # Get file paths\n",
    "        volume_files = sorted([os.path.join(volumes_dir, f) for f in os.listdir(volumes_dir) if f.endswith('.raw')])\n",
    "        mesh_files = sorted([os.path.join(meshes_dir, f) for f in os.listdir(meshes_dir) if f.endswith('.ply')])\n",
    "\n",
    "        def preprocess(volume_path, mesh_path):\n",
    "            # Load and normalize volume\n",
    "            with open(volume_path, 'rb') as f:\n",
    "                volume = np.frombuffer(f.read(), dtype=np.uint16).reshape((768, 768, 1280))\n",
    "            volume = volume / np.max(volume)  # Normalize to [0, 1]\n",
    "            \n",
    "            # Resize volume to input_shape\n",
    "            zoom_factors = [input_shape[0] / volume.shape[0], \n",
    "                            input_shape[1] / volume.shape[1], \n",
    "                            input_shape[2] / volume.shape[2]]\n",
    "            volume = zoom(volume, zoom_factors, order=1)  # Bilinear interpolation\n",
    "            volume = tf.expand_dims(volume, axis=-1)  # Add channel dimension\n",
    "\n",
    "            # Load mesh\n",
    "            mesh = trimesh.load(mesh_path, process=False)\n",
    "            vertices = mesh.vertices.astype(np.float32)\n",
    "            vertices = vertices - np.mean(vertices, axis=0)  # Center vertices\n",
    "            vertices = vertices / np.max(np.linalg.norm(vertices, axis=1))  # Normalize to unit sphere\n",
    "\n",
    "            # Pad vertices if fewer than num_vertices\n",
    "            if vertices.shape[0] < num_vertices:\n",
    "                padding = np.zeros((num_vertices - vertices.shape[0], 3), dtype=np.float32)\n",
    "                vertices = np.vstack([vertices, padding])\n",
    "            else:\n",
    "                vertices = vertices[:num_vertices]\n",
    "\n",
    "            return volume, vertices\n",
    "\n",
    "        def generator():\n",
    "            for vol_path, mesh_path in zip(volume_files, mesh_files):\n",
    "                yield preprocess(vol_path, mesh_path)\n",
    "\n",
    "        dataset = tf.data.Dataset.from_generator(\n",
    "            generator,\n",
    "            output_signature=(\n",
    "                tf.TensorSpec(shape=(input_shape[0], input_shape[1], input_shape[2], 1), dtype=tf.float32),\n",
    "                tf.TensorSpec(shape=(num_vertices, 3), dtype=tf.float32)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49facc3",
   "metadata": {},
   "source": [
    "### Training and Evaluation\n",
    "\n",
    "#### Training Process\n",
    "The training process focused on enabling the model to predict accurate 3D surface meshes for volumetric scans using the provided training data. The dataset was already split into distinct training and testing folders:\n",
    "##### Training Set:\n",
    "- 89 volumetric scans in .raw format.\n",
    "- 5 reference meshes in .ply format corresponding to scans 001-005.\n",
    "The model was trained using the scans and their corresponding meshes to learn meaningful spatial patterns and predict mesh vertex coordinates.\n",
    "1. Optimization Setup\n",
    "- Loss Function: Mean Squared Error (MSE) to minimize the distance between predicted and ground truth mesh vertices.\n",
    "- Optimizer: Adam optimizer with an initial learning rate of 0.0001, chosen for its efficiency and adaptability.\n",
    "- Batch Size: Training was conducted in batches of 2 to balance memory usage and convergence speed.\n",
    "2. Epochs: The model was trained for 30 epochs. This duration was sufficient to observe meaningful convergence in loss values while avoiding overfitting.\n",
    "\n",
    "#### Evaluation Metrics\n",
    "To evaluate the quality of the generated meshes, we used the following metrics:\n",
    "1. Chamfer Distance measures the average bidirectional distance between the predicted and ground truth point clouds. It evaluates both how complete and accurate the predictions are.\n",
    "2. Hausdorff Distance captures the maximum distance between the predicted and ground truth point clouds, highlighting the worst-case discrepancies.\n",
    "\n",
    "These metrics directly measure the geometric similarity between predicted and ground truth meshes, providing comprehensive performance insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "736c15af-3298-4054-b072-d74f30359d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 28s/step - loss: 0.1112 - mse: 0.1112 - val_loss: 0.1484 - val_mse: 0.1484\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\": \n",
    "    volumes_dir = \"training/volumes\"\n",
    "    meshes_dir = \"training/meshes\"\n",
    "\n",
    "    dataset = VolumetricMeshDataset(volumes_dir, meshes_dir)\n",
    "    train_size = int(0.8 * len(list(dataset)))\n",
    "    test_size = len(list(dataset)) - train_size\n",
    "\n",
    "    train_dataset = dataset.take(train_size).batch(2).prefetch(tf.data.AUTOTUNE)\n",
    "    test_dataset = dataset.skip(train_size).batch(2).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    # Create model\n",
    "    model = VolumetricToMeshModel()\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "                loss=tf.keras.losses.MeanSquaredError(),\n",
    "                metrics=[\"mse\"])\n",
    "\n",
    "    # Fit the model\n",
    "    model.fit(train_dataset, epochs=1, validation_data=test_dataset)\n",
    "    model.save(\"source/volumetric_to_mesh_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "759159a8-d662-494b-992d-4442faf40cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chamfer Distance Function\n",
    "def chamfer_distance(predicted, ground_truth):\n",
    "    \"\"\"\n",
    "    Computes the Chamfer Distance between two point clouds.\n",
    "    \"\"\"\n",
    "    dists_pred_to_gt = tf.reduce_min(\n",
    "        tf.reduce_sum((tf.expand_dims(predicted, axis=1) - tf.expand_dims(ground_truth, axis=0))**2, axis=-1), axis=1\n",
    "    )\n",
    "    dists_gt_to_pred = tf.reduce_min(\n",
    "        tf.reduce_sum((tf.expand_dims(ground_truth, axis=1) - tf.expand_dims(predicted, axis=0))**2, axis=-1), axis=1\n",
    "    )\n",
    "    chamfer = tf.reduce_mean(dists_pred_to_gt) + tf.reduce_mean(dists_gt_to_pred)\n",
    "    return chamfer.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d6708cc4-8e61-4145-bf55-ad6ecd88aaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hausdorff Distance Function\n",
    "def hausdorff_distance(predicted, ground_truth):\n",
    "    \"\"\"\n",
    "    Computes the Hausdorff Distance between two point clouds.\n",
    "    \"\"\"\n",
    "    dists_pred_to_gt = tf.reduce_min(\n",
    "        tf.reduce_sum((tf.expand_dims(predicted, axis=1) - tf.expand_dims(ground_truth, axis=0))**2, axis=-1), axis=1\n",
    "    )\n",
    "    dists_gt_to_pred = tf.reduce_min(\n",
    "        tf.reduce_sum((tf.expand_dims(ground_truth, axis=1) - tf.expand_dims(predicted, axis=0))**2, axis=-1), axis=1\n",
    "    )\n",
    "    hausdorff = max(tf.reduce_max(dists_pred_to_gt).numpy(), tf.reduce_max(dists_gt_to_pred).numpy())\n",
    "    return hausdorff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "770a45e3-ce7f-48cb-9641-f0873f89b952",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VolumetricToMeshModel(tf.keras.Model):\n",
    "    def __init__(self, latent_dim=1024, num_vertices=10000, **kwargs):\n",
    "        super(VolumetricToMeshModel, self).__init__(**kwargs)\n",
    "        self.latent_dim = latent_dim\n",
    "        self.num_vertices = num_vertices\n",
    "\n",
    "        self.backbone = tf.keras.Sequential([\n",
    "            tf.keras.layers.Conv3D(16, kernel_size=3, strides=1, padding=\"same\", activation=\"relu\"),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.MaxPooling3D(pool_size=2, strides=2),\n",
    "\n",
    "            tf.keras.layers.Conv3D(32, kernel_size=3, strides=1, padding=\"same\", activation=\"relu\"),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.MaxPooling3D(pool_size=2, strides=2),\n",
    "\n",
    "            tf.keras.layers.Conv3D(64, kernel_size=3, strides=1, padding=\"same\", activation=\"relu\"),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.MaxPooling3D(pool_size=2, strides=2),\n",
    "\n",
    "            tf.keras.layers.Conv3D(128, kernel_size=3, strides=1, padding=\"same\", activation=\"relu\"),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.GlobalAveragePooling3D()\n",
    "        ])\n",
    "\n",
    "        self.fc = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(latent_dim, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(num_vertices * 3)\n",
    "        ])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.backbone(inputs)\n",
    "        x = self.fc(x)\n",
    "        return tf.reshape(x, (-1, tf.shape(x)[1] // 3, 3))\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(VolumetricToMeshModel, self).get_config()\n",
    "        config.update({\n",
    "            \"latent_dim\": self.latent_dim,\n",
    "            \"num_vertices\": self.num_vertices\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e989e8f-ff0f-40b1-9f79-1ac647987250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\My Lan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:204: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the saved model\n",
    "model = tf.keras.models.load_model(\n",
    "    \"source/volumetric_to_mesh_model.keras\",\n",
    "    custom_objects={\"VolumetricToMeshModel\": VolumetricToMeshModel}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3696d5",
   "metadata": {},
   "source": [
    "#### Testing Process\n",
    "After training, the model was evaluated on the separate testing dataset:\n",
    "##### Testing Set:\n",
    "- 10 volumetric scans in .raw format.\n",
    "- 10 corresponding meshes in .ply format.\n",
    "\n",
    "The model was applied to these unseen scans, generating predicted meshes for comparison with the ground truth. Chamfer and Hausdorff distances were computed for each prediction to quantify accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "35704893-35ce-4c44-ac9d-593a3001b979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing data directories\n",
    "test_volumes_dir = \"testing/volumes\"\n",
    "test_meshes_dir = \"testing/meshes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f540d3d9-99e8-46c2-97e5-48f41ab9027a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare test dataset\n",
    "def preprocess(volume_path, mesh_path):\n",
    "    with open(volume_path, 'rb') as f:\n",
    "        volume = np.frombuffer(f.read(), dtype=np.uint16).reshape((768, 768, 1280))\n",
    "    volume = volume / np.max(volume)\n",
    "    zoom_factors = [128 / volume.shape[0], 128 / volume.shape[1], 128 / volume.shape[2]]\n",
    "    volume = zoom(volume, zoom_factors, order=1)\n",
    "    volume = tf.expand_dims(volume, axis=-1)\n",
    "    mesh = trimesh.load(mesh_path, process=False)\n",
    "    vertices = mesh.vertices.astype(np.float32)\n",
    "    vertices = vertices - np.mean(vertices, axis=0)\n",
    "    vertices = vertices / np.max(np.linalg.norm(vertices, axis=1))\n",
    "    return volume, vertices\n",
    "\n",
    "def test_generator():\n",
    "    volume_files = sorted([os.path.join(test_volumes_dir, f) for f in os.listdir(test_volumes_dir) if f.endswith('.raw')])\n",
    "    mesh_files = sorted([os.path.join(test_meshes_dir, f) for f in os.listdir(test_meshes_dir) if f.endswith('.ply')])\n",
    "    for vol_path, mesh_path in zip(volume_files, mesh_files):\n",
    "        yield preprocess(vol_path, mesh_path)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_generator(\n",
    "    test_generator,\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(128, 128, 128, 1), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(None, 3), dtype=tf.float32)\n",
    "    )\n",
    ").batch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b64d48-6936-464d-914e-532496c51b46",
   "metadata": {},
   "source": [
    "Due to a limit in computer storage and processing speed, we must manually paste one test file at a time into the testing folder to avoid crashing the computer. The code remained the same with the _for_ loops to emphasize that in real-world application, which often comes with a more powerful computer, the model will be able to evaluate multiple test cases at once. As a result, we got the Chamfer and Hausdorff distances for all 10 test cases, except for the Hausdorff distance results for the 4th test case because our computer kept crashing.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "23f81d66-500b-47d6-b85f-56adbb18ab64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step\n",
      "Average Chamfer Distance: 1.3098429441452026\n"
     ]
    }
   ],
   "source": [
    "# Evaluate metrics for file 1\n",
    "chamfer_scores = []\n",
    "\n",
    "for volume_batch, gt_mesh_batch in test_dataset:\n",
    "    predicted_mesh_batch = model.predict(volume_batch)\n",
    "    for predicted, ground_truth in zip(predicted_mesh_batch, gt_mesh_batch):\n",
    "        chamfer_scores.append(chamfer_distance(predicted, ground_truth))\n",
    "\n",
    "# Calculate average scores\n",
    "avg_chamfer = np.mean(chamfer_scores)\n",
    "print(f\"Average Chamfer Distance: {avg_chamfer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3846e4f5-4c7e-4470-bfcd-0100c9008d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step\n",
      "Average Chamfer Distance: 0.9633491635322571\n"
     ]
    }
   ],
   "source": [
    "# Evaluate metrics for file 2\n",
    "chamfer_scores = []\n",
    "\n",
    "for volume_batch, gt_mesh_batch in test_dataset:\n",
    "    predicted_mesh_batch = model.predict(volume_batch)\n",
    "    for predicted, ground_truth in zip(predicted_mesh_batch, gt_mesh_batch):\n",
    "        chamfer_scores.append(chamfer_distance(predicted, ground_truth))\n",
    "\n",
    "# Calculate average scores\n",
    "avg_chamfer = np.mean(chamfer_scores)\n",
    "print(f\"Average Chamfer Distance: {avg_chamfer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d11d3190-4574-48c6-b813-47b8f033b3a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 795ms/step\n",
      "Average Chamfer Distance: 0.8123236894607544\n"
     ]
    }
   ],
   "source": [
    "# Evaluate metrics for file 3\n",
    "chamfer_scores = []\n",
    "\n",
    "for volume_batch, gt_mesh_batch in test_dataset:\n",
    "    predicted_mesh_batch = model.predict(volume_batch)\n",
    "    for predicted, ground_truth in zip(predicted_mesh_batch, gt_mesh_batch):\n",
    "        chamfer_scores.append(chamfer_distance(predicted, ground_truth))\n",
    "\n",
    "# Calculate average scores\n",
    "avg_chamfer = np.mean(chamfer_scores)\n",
    "print(f\"Average Chamfer Distance: {avg_chamfer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "67d62ee9-a2f4-4cca-8a0b-137d96ec2652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 872ms/step\n",
      "Average Chamfer Distance: 0.44448643922805786\n"
     ]
    }
   ],
   "source": [
    "# Evaluate metrics for file 4\n",
    "chamfer_scores = []\n",
    "\n",
    "for volume_batch, gt_mesh_batch in test_dataset:\n",
    "    predicted_mesh_batch = model.predict(volume_batch)\n",
    "    for predicted, ground_truth in zip(predicted_mesh_batch, gt_mesh_batch):\n",
    "        chamfer_scores.append(chamfer_distance(predicted, ground_truth))\n",
    "\n",
    "# Calculate average scores\n",
    "avg_chamfer = np.mean(chamfer_scores)\n",
    "print(f\"Average Chamfer Distance: {avg_chamfer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "49cec875-3a69-439a-b95e-e9842da0954e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step\n",
      "Average Chamfer Distance: 0.3655959367752075\n"
     ]
    }
   ],
   "source": [
    "# Evaluate metrics for file 5\n",
    "chamfer_scores = []\n",
    "\n",
    "for volume_batch, gt_mesh_batch in test_dataset:\n",
    "    predicted_mesh_batch = model.predict(volume_batch)\n",
    "    for predicted, ground_truth in zip(predicted_mesh_batch, gt_mesh_batch):\n",
    "        chamfer_scores.append(chamfer_distance(predicted, ground_truth))\n",
    "\n",
    "# Calculate average scores\n",
    "avg_chamfer = np.mean(chamfer_scores)\n",
    "print(f\"Average Chamfer Distance: {avg_chamfer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "de21e99c-d6da-49ae-8e0d-982af072bb6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step\n",
      "Average Chamfer Distance: 0.45561835169792175\n"
     ]
    }
   ],
   "source": [
    "# Evaluate metrics for file 6\n",
    "chamfer_scores = []\n",
    "\n",
    "for volume_batch, gt_mesh_batch in test_dataset:\n",
    "    predicted_mesh_batch = model.predict(volume_batch)\n",
    "    for predicted, ground_truth in zip(predicted_mesh_batch, gt_mesh_batch):\n",
    "        chamfer_scores.append(chamfer_distance(predicted, ground_truth))\n",
    "\n",
    "# Calculate average scores\n",
    "avg_chamfer = np.mean(chamfer_scores)\n",
    "print(f\"Average Chamfer Distance: {avg_chamfer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3a0269f2-d4b3-4d31-870e-74e28dae23d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step\n",
      "Average Chamfer Distance: 0.46415770053863525\n"
     ]
    }
   ],
   "source": [
    "# Evaluate metrics for file 7\n",
    "chamfer_scores = []\n",
    "\n",
    "for volume_batch, gt_mesh_batch in test_dataset:\n",
    "    predicted_mesh_batch = model.predict(volume_batch)\n",
    "    for predicted, ground_truth in zip(predicted_mesh_batch, gt_mesh_batch):\n",
    "        chamfer_scores.append(chamfer_distance(predicted, ground_truth))\n",
    "\n",
    "# Calculate average scores\n",
    "avg_chamfer = np.mean(chamfer_scores)\n",
    "print(f\"Average Chamfer Distance: {avg_chamfer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8c6bf2ff-a741-46aa-a7e6-fff7aa416330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step\n",
      "Average Chamfer Distance: 0.3692156970500946\n"
     ]
    }
   ],
   "source": [
    "# Evaluate metrics for file 8\n",
    "chamfer_scores = []\n",
    "\n",
    "for volume_batch, gt_mesh_batch in test_dataset:\n",
    "    predicted_mesh_batch = model.predict(volume_batch)\n",
    "    for predicted, ground_truth in zip(predicted_mesh_batch, gt_mesh_batch):\n",
    "        chamfer_scores.append(chamfer_distance(predicted, ground_truth))\n",
    "\n",
    "# Calculate average scores\n",
    "avg_chamfer = np.mean(chamfer_scores)\n",
    "print(f\"Average Chamfer Distance: {avg_chamfer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "38c2e97f-f5fe-43f5-9675-c29ddb502130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step\n",
      "Average Chamfer Distance: 0.4162712097167969\n"
     ]
    }
   ],
   "source": [
    "# Evaluate metrics for file 9\n",
    "chamfer_scores = []\n",
    "\n",
    "for volume_batch, gt_mesh_batch in test_dataset:\n",
    "    predicted_mesh_batch = model.predict(volume_batch)\n",
    "    for predicted, ground_truth in zip(predicted_mesh_batch, gt_mesh_batch):\n",
    "        chamfer_scores.append(chamfer_distance(predicted, ground_truth))\n",
    "\n",
    "# Calculate average scores\n",
    "avg_chamfer = np.mean(chamfer_scores)\n",
    "print(f\"Average Chamfer Distance: {avg_chamfer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ef36483b-a9be-4798-ac85-41729d531603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 843ms/step\n",
      "Average Chamfer Distance: 0.47973278164863586\n"
     ]
    }
   ],
   "source": [
    "# Evaluate metrics for file 10\n",
    "chamfer_scores = []\n",
    "\n",
    "for volume_batch, gt_mesh_batch in test_dataset:\n",
    "    predicted_mesh_batch = model.predict(volume_batch)\n",
    "    for predicted, ground_truth in zip(predicted_mesh_batch, gt_mesh_batch):\n",
    "        chamfer_scores.append(chamfer_distance(predicted, ground_truth))\n",
    "\n",
    "# Calculate average scores\n",
    "avg_chamfer = np.mean(chamfer_scores)\n",
    "print(f\"Average Chamfer Distance: {avg_chamfer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "60544e63-014f-4124-84be-ec59b9fd8ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step\n",
      "Average Hausdorff Distance: 0.9990211129188538\n"
     ]
    }
   ],
   "source": [
    "# Evaluate metrics for file 1\n",
    "hausdorff_scores = []\n",
    "\n",
    "for volume_batch, gt_mesh_batch in test_dataset:\n",
    "    predicted_mesh_batch = model.predict(volume_batch)\n",
    "    for predicted, ground_truth in zip(predicted_mesh_batch, gt_mesh_batch):\n",
    "        hausdorff_scores.append(hausdorff_distance(predicted, ground_truth))\n",
    "\n",
    "# Calculate average scores\n",
    "avg_hausdorff = np.mean(hausdorff_scores)\n",
    "print(f\"Average Hausdorff Distance: {avg_hausdorff}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "981f7b9b-863e-43da-9886-571dfbeed446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step\n",
      "Average Hausdorff Distance: 0.9987767338752747\n"
     ]
    }
   ],
   "source": [
    "# Evaluate metrics for file 2\n",
    "hausdorff_scores = []\n",
    "\n",
    "for volume_batch, gt_mesh_batch in test_dataset:\n",
    "    predicted_mesh_batch = model.predict(volume_batch)\n",
    "    for predicted, ground_truth in zip(predicted_mesh_batch, gt_mesh_batch):\n",
    "        hausdorff_scores.append(hausdorff_distance(predicted, ground_truth))\n",
    "\n",
    "# Calculate average scores\n",
    "avg_hausdorff = np.mean(hausdorff_scores)\n",
    "print(f\"Average Hausdorff Distance: {avg_hausdorff}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "91054616-eb0e-4fef-ac22-f04bf530f28e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step\n",
      "Average Hausdorff Distance: 0.9989096522331238\n"
     ]
    }
   ],
   "source": [
    "# Evaluate metrics for file 3\n",
    "hausdorff_scores = []\n",
    "\n",
    "for volume_batch, gt_mesh_batch in test_dataset:\n",
    "    predicted_mesh_batch = model.predict(volume_batch)\n",
    "    for predicted, ground_truth in zip(predicted_mesh_batch, gt_mesh_batch):\n",
    "        hausdorff_scores.append(hausdorff_distance(predicted, ground_truth))\n",
    "\n",
    "# Calculate average scores\n",
    "avg_hausdorff = np.mean(hausdorff_scores)\n",
    "print(f\"Average Hausdorff Distance: {avg_hausdorff}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc300c6-b244-4ad1-aa6c-e28f28e77d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n"
     ]
    }
   ],
   "source": [
    "# Evaluate metrics for file 4\n",
    "hausdorff_scores = []\n",
    "\n",
    "for volume_batch, gt_mesh_batch in test_dataset:\n",
    "    predicted_mesh_batch = model.predict(volume_batch)\n",
    "    for predicted, ground_truth in zip(predicted_mesh_batch, gt_mesh_batch):\n",
    "        hausdorff_scores.append(hausdorff_distance(predicted, ground_truth))\n",
    "\n",
    "# Calculate average scores\n",
    "avg_hausdorff = np.mean(hausdorff_scores)\n",
    "print(f\"Average Hausdorff Distance: {avg_hausdorff}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1dd65ba4-6eda-4ce7-9bc2-ba83e1441249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step\n",
      "Average Hausdorff Distance: 0.9987020492553711\n"
     ]
    }
   ],
   "source": [
    "# Evaluate metrics for file 5\n",
    "hausdorff_scores = []\n",
    "\n",
    "for volume_batch, gt_mesh_batch in test_dataset:\n",
    "    predicted_mesh_batch = model.predict(volume_batch)\n",
    "    for predicted, ground_truth in zip(predicted_mesh_batch, gt_mesh_batch):\n",
    "        hausdorff_scores.append(hausdorff_distance(predicted, ground_truth))\n",
    "\n",
    "# Calculate average scores\n",
    "avg_hausdorff = np.mean(hausdorff_scores)\n",
    "print(f\"Average Hausdorff Distance: {avg_hausdorff}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f2544dfb-d429-4481-a513-f7dd3e417ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step\n",
      "Average Hausdorff Distance: 0.9987960457801819\n"
     ]
    }
   ],
   "source": [
    "# Evaluate metrics for file 6\n",
    "hausdorff_scores = []\n",
    "\n",
    "for volume_batch, gt_mesh_batch in test_dataset:\n",
    "    predicted_mesh_batch = model.predict(volume_batch)\n",
    "    for predicted, ground_truth in zip(predicted_mesh_batch, gt_mesh_batch):\n",
    "        hausdorff_scores.append(hausdorff_distance(predicted, ground_truth))\n",
    "\n",
    "# Calculate average scores\n",
    "avg_hausdorff = np.mean(hausdorff_scores)\n",
    "print(f\"Average Hausdorff Distance: {avg_hausdorff}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e401332f-3394-48ac-9a44-a86767fb6daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step\n",
      "Average Hausdorff Distance: 0.9985036849975586\n"
     ]
    }
   ],
   "source": [
    "# Evaluate metrics for file 7\n",
    "hausdorff_scores = []\n",
    "\n",
    "for volume_batch, gt_mesh_batch in test_dataset:\n",
    "    predicted_mesh_batch = model.predict(volume_batch)\n",
    "    for predicted, ground_truth in zip(predicted_mesh_batch, gt_mesh_batch):\n",
    "        hausdorff_scores.append(hausdorff_distance(predicted, ground_truth))\n",
    "\n",
    "# Calculate average scores\n",
    "avg_hausdorff = np.mean(hausdorff_scores)\n",
    "print(f\"Average Hausdorff Distance: {avg_hausdorff}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5fd57b2c-2494-4936-8342-818816e807e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step\n",
      "Average Hausdorff Distance: 0.9987719058990479\n"
     ]
    }
   ],
   "source": [
    "# Evaluate metrics for file 8\n",
    "hausdorff_scores = []\n",
    "\n",
    "for volume_batch, gt_mesh_batch in test_dataset:\n",
    "    predicted_mesh_batch = model.predict(volume_batch)\n",
    "    for predicted, ground_truth in zip(predicted_mesh_batch, gt_mesh_batch):\n",
    "        hausdorff_scores.append(hausdorff_distance(predicted, ground_truth))\n",
    "\n",
    "# Calculate average scores\n",
    "avg_hausdorff = np.mean(hausdorff_scores)\n",
    "print(f\"Average Hausdorff Distance: {avg_hausdorff}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3858cd9c-50c6-4bc6-83c2-d31271ca2a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step\n",
      "Average Hausdorff Distance: 0.998645544052124\n"
     ]
    }
   ],
   "source": [
    "# Evaluate metrics for file 9\n",
    "hausdorff_scores = []\n",
    "\n",
    "for volume_batch, gt_mesh_batch in test_dataset:\n",
    "    predicted_mesh_batch = model.predict(volume_batch)\n",
    "    for predicted, ground_truth in zip(predicted_mesh_batch, gt_mesh_batch):\n",
    "        hausdorff_scores.append(hausdorff_distance(predicted, ground_truth))\n",
    "\n",
    "# Calculate average scores\n",
    "avg_hausdorff = np.mean(hausdorff_scores)\n",
    "print(f\"Average Hausdorff Distance: {avg_hausdorff}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fecf2370-ce10-47de-9502-92d528c37a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 842ms/step\n",
      "Average Hausdorff Distance: 0.999098539352417\n"
     ]
    }
   ],
   "source": [
    "# Evaluate metrics for file 10\n",
    "hausdorff_scores = []\n",
    "\n",
    "for volume_batch, gt_mesh_batch in test_dataset:\n",
    "    predicted_mesh_batch = model.predict(volume_batch)\n",
    "    for predicted, ground_truth in zip(predicted_mesh_batch, gt_mesh_batch):\n",
    "        hausdorff_scores.append(hausdorff_distance(predicted, ground_truth))\n",
    "\n",
    "# Calculate average scores\n",
    "avg_hausdorff = np.mean(hausdorff_scores)\n",
    "print(f\"Average Hausdorff Distance: {avg_hausdorff}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d96ad1f",
   "metadata": {},
   "source": [
    "#### Results\n",
    "The evaluation metrics revealed that the Chamfer and Hausdorff distances were approximately 0.61 (for all 10 test sets) and 0.99 (for 9 test sets except for the 4th one) on average, respectively. While this might seem significant at first glance, it is important to consider the context of the input data:\n",
    "- The input volumetric scans are large, spanning dimensions of (128, 128, 128) after preprocessing.\n",
    "- A distance of 1 represents a small error relative to the overall size of the meshes and the level of detail in the data.\n",
    "\n",
    "These results indicate that the model performs reasonably well, capturing the overall structure of the meshes while maintaining geometric accuracy. While there is room for improvement, the current performance demonstrates a strong foundation for further refinement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88862fb0",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "This project tackled the challenging task of predicting 3D surface meshes from volumetric ultrasound scans, a problem that requires the model to understand complex spatial relationships. Despite limitations such as a small number of reference meshes, the results demonstrate the potential of machine learning in this domain. With Chamfer and Hausdorff distances averaging around 1, the model shows that it can produce predictions that are accurate relative to the size and complexity of the input data.\n",
    "\n",
    "Key achievements of the project include:\n",
    "\n",
    "- The successful design and implementation of the VolumetricToMeshModel, a custom 3D-CNN-based architecture tailored for volumetric data.\n",
    "- Thoughtful preprocessing of the volumetric scans and meshes, ensuring consistency and alignment with the model’s input requirements.\n",
    "- Robust evaluation using metrics that provided clear insights into how well the model performed.\n",
    "\n",
    "These outcomes indicate a strong foundation for future work, highlighting both the promise of this approach and the opportunities for refinement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d60c50e",
   "metadata": {},
   "source": [
    "### Future Work\n",
    "While the current results are promising, there are several areas for improvement that could enhance the model’s performance and usability:\n",
    "\n",
    "1. Processing time and storage: A major challenge for this project was a computational limitation in storage and processing time. In this case, we used a 952GB computer to store the data and run the test cases. However, we still need to constantly delete unecessary folders, clear cache and cookies, and interupt Visual Studio Code and Jupyter Lab on time to avoid crashing the computer. This highlights the importance of more robust computational resources and code optimization in real-world application. In future competitions, we aim to participate better equipped, bringing additional laptops or high-performance computing resources with sufficient memory and processing capabilities.\n",
    "\n",
    "2. Optimizing the Testing Process: Due to limited computational resources, we were only able to process one file at a time during testing. This meant temporarily removing other files to manage disk space and memory. Given more time, we would optimize the code to handle multiple files in parallel without requiring such manual interventions.\n",
    "\n",
    "3. Refining the Model Architecture: The current model performed well, but there’s potential to enhance it further. Incorporating advanced techniques such as attention mechanisms or exploring transformer-based architectures could improve both accuracy and generalization.\n",
    "\n",
    "4. Expand Training and Testing dataset: Testing on a larger and more diverse dataset would provide a deeper understanding of the model’s strengths and limitations, especially in edge cases. As a result, a more powerful computer is necessary to ensure optimal performance, particularly when the results are highly sensitive.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4efa556",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
